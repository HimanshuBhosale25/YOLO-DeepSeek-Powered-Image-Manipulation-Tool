# AI Image Transformer: Deep Learning Powered Image Editing with a User-Friendly Web Interface ğŸ§ âœ¨ğŸŒ

**This project demonstrates the power of deepseek-r1-distill-llama-70b model to handle and manipulate complex prompts while utilizing YOLOv8l-seg model for segmentation and Pillow library for image manipulation, packaged within a user-friendly web application. It highlights the synergy between advanced AI models and modern frontend development, making complex image editing accessible to professional editors as well as general audience. ğŸš€**

## Key Deep Learning and AI Features ğŸŒŸ

* **AI-Driven Image Manipulation:** Witness the transformative power of large language models as your text prompts are translated into precise and nuanced image edits. ğŸ§ 
* **Advanced Object Segmentation (YOLOv8):** Leveraging Ultralytics' YOLOv8l-seg for accurate object detection and segmentation, enabling precise, targeted edits on specific image regions. ğŸ¯
* **Natural Language Understanding (Groq API):** Integrating with the Groq API to harness deepseek-r1-distill-llama-70b for understanding and interpreting user prompts, translating them into actionable image adjustments. ğŸ’¬
* **Sophisticated Masking and Blending with OpenCV:** Implementing advanced masking, Inverted Masking and blending techniques using OpenCV, ensuring seamless integration of AI-driven edits for realistic results. ğŸ­
* **End-to-End Deep Learning Pipeline:** Demonstrating a complete deep learning pipeline, from natural language input to image output, showcasing the project's AI capabilities. ğŸ”„

## User-Friendly Web Interface (React) ğŸŒ

* **Intuitive React Frontend:** Provides a seamless and engaging user experience, showcasing modern web development practices with a clean, glassmorphic design and smooth transitions. ğŸ‘€
* **Session-Based Editing with Persistent State:** Allows users to stack multiple edits, demonstrating the model's ability to maintain context and refine results across sessions, all managed within the frontend. ğŸ”„
* **Real-time Previews:** Displays original and processed images side-by-side, providing instant feedback on the AI's performance within the browser. ğŸ–¼ï¸
* **Download Functionality:** Enables users to easily download edited images, completing the end-to-end user experience, handled efficiently by the frontend. ğŸ“¥
* **Responsive Design:** Ensures a consistent and enjoyable experience across various devices, showcasing frontend adaptability. ğŸ“±ğŸ’»

## Screenshots of UI:ğŸ“¸

### **Welcome Screen:**
![WS](images/i4.png) 


### **Tutorial:**
![T](images/i5.png)


### **Example 1:**
![Ex1](images/i6.png)


### **Example 2:**
![Ex2](images/i7.png)


### **Example 3:**
![Ex3](images/i8.png)


## Segmentation and Masking:ğŸ“¸

### **Original Image:**
![OG](images/i1.png)


### **Object Detection:**
![OD](images/i2.png)


### **Object Making:**
![OM](images/i3.png)




## Getting Started (Focus on AI and Web Integration) ğŸ

### Prerequisites ğŸ“‹

* Node.js and npm (or yarn) installed for frontend development. ğŸ“¦
* Python 3.11 with required deep learning and AI libraries (see Dependencies). ğŸ
* A running backend server (see Backend Setup). âš™ï¸

### Installation ğŸ› ï¸

1.  **Clone the repository:**

    ```bash
    git clone https://github.com/HimanshuBhosale25/YOLO-DeepSeek-Powered-Image-Manipulation-Tool.git
    cd ai-image-editor
    ```

2.  **Install frontend dependencies:**

    ```bash
    npm install
    ```

3.  **Run the frontend:**

    ```bash
    npm start
    ```

    Open your browser and navigate to `http://localhost:5173`. ğŸŒ

4.  **Backend Setup:**

    * Navigate to the backend directory. ğŸ“‚
    * Install backend dependencies (refer to backend documentation for specific instructions. Focus on the AI and deep learning libraries). â¬‡ï¸
    * Set the `GROQ_API_KEY` environment variable. ğŸ”‘
    * Run the FastAPI application (e.g., `uvicorn main:app --reload`). â–¶ï¸
    * Ensure the backend is accessible at `http://localhost:8000`. ğŸš€

### Usage (AI and Web Interaction) ğŸ’¡

1.  **Upload an image:** (Using the web interface to provide input for the Large Language model). ğŸ–¼ï¸
2.  **Enter a descriptive text prompt:** (To guide the AI's image editing process through the web interface). ğŸ“
3.  **Process the image:** (Using the web interface to trigger the deep learning pipeline). âœ…
4.  **View the results:** (Using the web interface to observe the AI's output). ğŸ‘€
5.  **Download:** (Using the web interface to save the AI-processed image). ğŸ’¾

## Technologies Used:ğŸ“¦

* **Backend (Python):**
    * FastAPI âš¡
    * Uvicorn ğŸ¦„
    * Pillow (PIL) ğŸ–¼ï¸
    * OpenCV (cv2) ğŸ‘ï¸
    * Ultralytics (YOLOv8) ğŸ¯
    * Groq ğŸ¤–

* **Frontend (React):**
    * React âš›ï¸
    * React Router DOM ğŸ›£ï¸
    * Axios ğŸ“¡


## Contributing (AI and Web Focus) ğŸ¤

Contributions focused on improving the deep learning models, AI integration, image processing algorithms, and the user-friendly web interface are highly encouraged. ğŸ›âœ¨ğŸ“ˆ

## License ğŸ“œ

This project is licensed under the MIT License. ğŸ“